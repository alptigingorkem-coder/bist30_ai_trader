# Development Log - 2026-02-07

## ğŸ› ï¸ Gece Oturumu (Model Optimizasyonu ve Hata AyÄ±klama)
Negatif Alpha sorununu Ã§Ã¶zmek ve model stabilitesini saÄŸlamak iÃ§in kapsamlÄ± bir analiz ve hata ayÄ±klama sÃ¼reci yÃ¼rÃ¼tÃ¼ldÃ¼.

### A. TFT Model Ã‡Ã¶kmesi (Model Collapse) TeÅŸhisi ve Ã‡Ã¶zÃ¼mÃ¼
- **Sorun:** TFT modeli eÄŸitildiÄŸinde varyansÄ±n `0.0000` olduÄŸu ve modelin sabit bir deÄŸer Ã¼rettiÄŸi (Ã¶ÄŸrenemediÄŸi) tespit edildi.
- **KÃ¶k Neden:** `models/transformer_model.py` iÃ§inde hedef deÄŸiÅŸken (Excess Return) normalizasyonu iÃ§in kullanÄ±lan `GroupNormalizer(transformation="softplus")` ayarÄ±. Borsa getirileri negatif deÄŸerler alabildiÄŸi iÃ§in `softplus` dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (negatifleri sÄ±fÄ±ra yaklaÅŸtÄ±rma/yok etme eÄŸilimi) veri kaybÄ±na yol aÃ§Ä±yordu.
- **Ã‡Ã¶zÃ¼m:** Transformasyon `None` (Standart Scaler) olarak deÄŸiÅŸtirildi.
- **SonuÃ§:** Varyans `0.0027` seviyesine Ã§Ä±karak modelin Ã¶ÄŸrenme yeteneÄŸi geri kazanÄ±ldÄ±.

### B. AltyapÄ± ve GPU HÄ±zlandÄ±rma Denemeleri
- **DirectML (AMD GPU):** Model eÄŸitimini hÄ±zlandÄ±rmak iÃ§in `torch-directml` entegrasyonu denendi.
- **Bulgular:**
  - PyTorch Lightning'in DirectML cihaz tipini (`privateuseone`) otomatik tanÄ±madÄ±ÄŸÄ± gÃ¶rÃ¼ldÃ¼.
  - Manuel accelerator tanÄ±mlarÄ± ve "hack" yÃ¶ntemleri (CPU accelerator + manuel `.to(device)`) denendi.
  - KÃ¼tÃ¼phane Ã§akÄ±ÅŸmalarÄ± (`scipy`/`sklearn` import hatalarÄ±) yaÅŸandÄ±.
- **Karar:** KararlÄ±lÄ±k (Stability) Ã¶nceliklendirilerek DirectML entegrasyonu ÅŸimdilik rafa kaldÄ±rÄ±ldÄ± ve kod tabanÄ± temizlendi. EÄŸitim CPU Ã¼zerinde gÃ¼venli moda alÄ±ndÄ±.

### C. Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± ve Stratejik Karar
Backtest sonuÃ§larÄ±na gÃ¶re strateji konfigÃ¼rasyonlarÄ± karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±:

| KonfigÃ¼rasyon | Getiri | Durum |
| :--- | :--- | :--- |
| **SL 3.0 / Weight 0.85 (Ensemble)** | **%25.83** | **TFT Negatif Etki** |
| SL 3.0 / Weight 1.0 (LGBM Only) | %31.84 | Baz Seviye |
| **SL 2.5 / Weight 1.0 (Optimize)** | **%34.02** | **En YÃ¼ksek Getiri** |

- **SonuÃ§:** Teknik olarak dÃ¼zeltilen TFT modeli, ÅŸu aÅŸamada stratejinin genel performansÄ±nÄ± aÅŸaÄŸÄ± Ã§ekmektedir (%31 -> %25).
- **Aksiyon:** KÄ±sa vadede **SL 2.5 / TP 6.0** (Optimize) ayarlarÄ±na dÃ¶nÃ¼lmesi ve TFT modelinin "Feature Engineering" Ã§alÄ±ÅŸmalarÄ± tamamlanana kadar devre dÄ±ÅŸÄ± bÄ±rakÄ±lmasÄ±na karar verildi.

## ğŸ“ Sonraki AdÄ±mlar
- Optimize edilmiÅŸ ayarlarla (SL 2.5, TP 6.0) canlÄ±/paper trading'e devam etmek.
- TFT modeli iÃ§in yeni feature'lar ( Sentiment Analysis, Daha derin makro veriler) araÅŸtÄ±rmak.
